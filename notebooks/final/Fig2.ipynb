{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pyuoi.linear_model.var import VAR\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from neurosim.models.var import VAR as VARss\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')\n",
    "from loaders import load_sabes\n",
    "from subspaces import estimate_autocorrelation\n",
    "from utils import apply_df_filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting (Sabes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = glob('/mnt/Secondary/data/sabes/*.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10591.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5115.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19691.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30174.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3979.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22075.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14768.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29959.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4854.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34663.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29330.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23172.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19418.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18724.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 32263.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28926.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22192.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30174.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30840.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 32263.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22310.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25731.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28926.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24672.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22192.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27776.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:21<00:00, 21.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:29<00:00, 29.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:24<00:00, 24.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:21<00:00, 21.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Check for non-empty S1 indices\n",
    "valid_data_files = [data_file for data_file in data_files if load_sabes(data_file, region='S1')['spike_rates'].shape[-1] != 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_size = []\n",
    "S1_size = []\n",
    "loco_files = glob.glob('/mnt/Secondary/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Setup a script that can, using MPI, scalably do the VAR fits on cross validated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/Secondary/data/sabes/indy_20160426_01.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170210_03.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170213_02.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170214_02.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170215_02.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170216_02.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170217_02.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170227_04.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170228_02.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170301_05.mat',\n",
       " '/mnt/Secondary/data/sabes/loco_20170302_02.mat']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each data file, fit OLS VAR(1), VAR(3), VAR(5) on *both* M1 and S1, as well as M1 and S1 jointly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to compare VAR performance to SSID in neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.98s/it]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 186it [00:11, 16.51it/s]\n",
      "Rows of VAR matrix processed: 86it [00:01, 46.36it/s]\n",
      "Rows of VAR matrix processed: 272it [00:28,  9.44it/s]\n",
      "Rows of VAR matrix processed: 186it [00:25,  7.35it/s]\n",
      "Rows of VAR matrix processed: 86it [00:03, 22.09it/s]\n",
      "Rows of VAR matrix processed: 272it [01:01,  4.45it/s]\n",
      "Rows of VAR matrix processed: 186it [00:42,  4.38it/s]\n",
      "Rows of VAR matrix processed: 86it [00:07, 11.52it/s]\n",
      "Rows of VAR matrix processed: 272it [01:58,  2.29it/s]\n",
      "Rows of VAR matrix processed: 186it [01:06,  2.79it/s]\n",
      "Rows of VAR matrix processed: 86it [00:10,  8.13it/s]\n",
      "Rows of VAR matrix processed: 272it [03:02,  1.49it/s]\n",
      "Rows of VAR matrix processed: 186it [01:36,  1.93it/s]\n",
      "Rows of VAR matrix processed: 86it [00:13,  6.50it/s]\n",
      "Rows of VAR matrix processed: 272it [04:36,  1.02s/it]\n",
      "Rows of VAR matrix processed: 186it [00:11, 16.23it/s]\n",
      "Rows of VAR matrix processed: 86it [00:01, 47.53it/s]\n",
      "Rows of VAR matrix processed: 272it [00:30,  9.03it/s]\n",
      "Rows of VAR matrix processed: 186it [00:25,  7.38it/s]\n",
      "Rows of VAR matrix processed: 86it [00:03, 21.73it/s]\n",
      "Rows of VAR matrix processed: 272it [01:00,  4.47it/s]\n",
      "Rows of VAR matrix processed: 186it [00:41,  4.49it/s]\n",
      "Rows of VAR matrix processed: 86it [00:07, 11.94it/s]\n",
      "Rows of VAR matrix processed: 272it [01:56,  2.33it/s]\n",
      "Rows of VAR matrix processed: 186it [01:05,  2.82it/s]\n",
      "Rows of VAR matrix processed: 86it [00:10,  8.03it/s]\n",
      "Rows of VAR matrix processed: 272it [02:57,  1.53it/s]\n",
      "Rows of VAR matrix processed: 186it [01:34,  1.97it/s]\n",
      "Rows of VAR matrix processed: 86it [00:13,  6.61it/s]\n",
      "Rows of VAR matrix processed: 272it [04:32,  1.00s/it]\n",
      "Rows of VAR matrix processed: 186it [00:11, 16.24it/s]\n",
      "Rows of VAR matrix processed: 86it [00:01, 46.02it/s]\n",
      "Rows of VAR matrix processed: 272it [00:29,  9.17it/s]\n",
      "Rows of VAR matrix processed: 186it [00:24,  7.47it/s]\n",
      "Rows of VAR matrix processed: 86it [00:03, 21.69it/s]\n",
      "Rows of VAR matrix processed: 272it [01:00,  4.47it/s]\n",
      "Rows of VAR matrix processed: 186it [00:41,  4.43it/s]\n",
      "Rows of VAR matrix processed: 86it [00:07, 12.24it/s]\n",
      "Rows of VAR matrix processed: 272it [01:57,  2.31it/s]\n",
      "Rows of VAR matrix processed: 186it [01:05,  2.83it/s]\n",
      "Rows of VAR matrix processed: 86it [00:10,  8.14it/s]\n",
      "Rows of VAR matrix processed: 272it [02:59,  1.52it/s]\n",
      "Rows of VAR matrix processed: 186it [01:35,  1.94it/s]\n",
      "Rows of VAR matrix processed: 86it [00:13,  6.53it/s]\n",
      "Rows of VAR matrix processed: 272it [04:28,  1.01it/s]\n",
      "Rows of VAR matrix processed: 186it [00:11, 16.15it/s]\n",
      "Rows of VAR matrix processed: 86it [00:01, 43.81it/s]\n",
      "Rows of VAR matrix processed: 272it [00:29,  9.27it/s]\n",
      "Rows of VAR matrix processed: 186it [00:25,  7.43it/s]\n",
      "Rows of VAR matrix processed: 86it [00:03, 22.41it/s]\n",
      "Rows of VAR matrix processed: 272it [01:01,  4.45it/s]\n",
      "Rows of VAR matrix processed: 186it [00:41,  4.43it/s]\n",
      "Rows of VAR matrix processed: 86it [00:07, 11.88it/s]\n",
      "Rows of VAR matrix processed: 272it [01:57,  2.32it/s]\n",
      "Rows of VAR matrix processed: 186it [01:05,  2.82it/s]\n",
      "Rows of VAR matrix processed: 86it [00:10,  8.25it/s]\n",
      "Rows of VAR matrix processed: 272it [02:59,  1.52it/s]\n",
      "Rows of VAR matrix processed: 186it [01:34,  1.98it/s]\n",
      "Rows of VAR matrix processed: 86it [00:12,  6.69it/s]\n",
      "Rows of VAR matrix processed: 272it [04:30,  1.00it/s]\n",
      "Rows of VAR matrix processed: 186it [00:11, 16.21it/s]\n",
      "Rows of VAR matrix processed: 86it [00:01, 43.55it/s]\n",
      "Rows of VAR matrix processed: 272it [00:28,  9.40it/s]\n",
      "Rows of VAR matrix processed: 186it [00:24,  7.54it/s]\n",
      "Rows of VAR matrix processed: 86it [00:03, 21.76it/s]\n",
      "Rows of VAR matrix processed: 272it [01:01,  4.46it/s]\n",
      "Rows of VAR matrix processed: 186it [00:42,  4.43it/s]\n",
      "Rows of VAR matrix processed: 86it [00:07, 12.23it/s]\n",
      "Rows of VAR matrix processed: 272it [01:57,  2.31it/s]\n",
      "Rows of VAR matrix processed: 186it [01:04,  2.87it/s]\n",
      "Rows of VAR matrix processed: 86it [00:10,  8.25it/s]\n",
      "Rows of VAR matrix processed: 272it [02:57,  1.53it/s]\n",
      "Rows of VAR matrix processed: 186it [01:35,  1.96it/s]\n",
      "Rows of VAR matrix processed: 86it [00:12,  6.70it/s]\n",
      "Rows of VAR matrix processed: 272it [04:30,  1.01it/s]\n",
      " 20%|██        | 1/5 [1:18:39<5:14:37, 4719.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:22<00:00, 22.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30174.85it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 13.19it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 12.87it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.76it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.66it/s]\n",
      "Rows of VAR matrix processed: 174it [00:46,  3.71it/s]\n",
      "Rows of VAR matrix processed: 174it [00:46,  3.71it/s]\n",
      "Rows of VAR matrix processed: 174it [01:10,  2.47it/s]\n",
      "Rows of VAR matrix processed: 174it [01:09,  2.49it/s]\n",
      "Rows of VAR matrix processed: 174it [01:40,  1.72it/s]\n",
      "Rows of VAR matrix processed: 174it [01:41,  1.72it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 12.98it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 12.76it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.68it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.73it/s]\n",
      "Rows of VAR matrix processed: 174it [00:46,  3.70it/s]\n",
      "Rows of VAR matrix processed: 174it [00:47,  3.69it/s]\n",
      "Rows of VAR matrix processed: 174it [01:10,  2.48it/s]\n",
      "Rows of VAR matrix processed: 174it [01:09,  2.50it/s]\n",
      "Rows of VAR matrix processed: 174it [01:40,  1.73it/s]\n",
      "Rows of VAR matrix processed: 174it [01:41,  1.72it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 12.65it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 12.65it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.75it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.75it/s]\n",
      "Rows of VAR matrix processed: 174it [00:47,  3.68it/s]\n",
      "Rows of VAR matrix processed: 174it [00:47,  3.66it/s]\n",
      "Rows of VAR matrix processed: 174it [01:08,  2.53it/s]\n",
      "Rows of VAR matrix processed: 174it [01:08,  2.52it/s]\n",
      "Rows of VAR matrix processed: 174it [01:41,  1.71it/s]\n",
      "Rows of VAR matrix processed: 174it [01:41,  1.72it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 12.76it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 12.62it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.69it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.75it/s]\n",
      "Rows of VAR matrix processed: 174it [00:47,  3.67it/s]\n",
      "Rows of VAR matrix processed: 174it [00:47,  3.66it/s]\n",
      "Rows of VAR matrix processed: 174it [01:08,  2.53it/s]\n",
      "Rows of VAR matrix processed: 174it [01:08,  2.53it/s]\n",
      "Rows of VAR matrix processed: 174it [01:42,  1.70it/s]\n",
      "Rows of VAR matrix processed: 174it [01:41,  1.71it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 12.62it/s]\n",
      "Rows of VAR matrix processed: 174it [00:13, 12.70it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.71it/s]\n",
      "Rows of VAR matrix processed: 174it [00:30,  5.73it/s]\n",
      "Rows of VAR matrix processed: 174it [00:47,  3.66it/s]\n",
      "Rows of VAR matrix processed: 174it [00:47,  3.67it/s]\n",
      "Rows of VAR matrix processed: 174it [01:09,  2.50it/s]\n",
      "Rows of VAR matrix processed: 174it [01:09,  2.51it/s]\n",
      "Rows of VAR matrix processed: 174it [01:42,  1.70it/s]\n",
      "Rows of VAR matrix processed: 174it [01:41,  1.72it/s]\n",
      " 40%|████      | 2/5 [2:02:50<2:55:08, 3502.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18808.54it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 86.35it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 86.70it/s]\n",
      "Rows of VAR matrix processed: 149it [00:04, 35.80it/s]\n",
      "Rows of VAR matrix processed: 149it [00:03, 37.72it/s]\n",
      "Rows of VAR matrix processed: 149it [00:07, 21.07it/s]\n",
      "Rows of VAR matrix processed: 149it [00:07, 21.16it/s]\n",
      "Rows of VAR matrix processed: 149it [00:11, 13.50it/s]\n",
      "Rows of VAR matrix processed: 149it [00:10, 13.71it/s]\n",
      "Rows of VAR matrix processed: 149it [00:18,  8.13it/s]\n",
      "Rows of VAR matrix processed: 149it [00:18,  8.14it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 88.32it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 81.36it/s]\n",
      "Rows of VAR matrix processed: 149it [00:04, 34.94it/s]\n",
      "Rows of VAR matrix processed: 149it [00:04, 35.82it/s]\n",
      "Rows of VAR matrix processed: 149it [00:06, 21.56it/s]\n",
      "Rows of VAR matrix processed: 149it [00:07, 21.19it/s]\n",
      "Rows of VAR matrix processed: 149it [00:10, 13.70it/s]\n",
      "Rows of VAR matrix processed: 149it [00:10, 13.77it/s]\n",
      "Rows of VAR matrix processed: 149it [00:18,  8.28it/s]\n",
      "Rows of VAR matrix processed: 149it [00:18,  8.13it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 85.41it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 77.12it/s]\n",
      "Rows of VAR matrix processed: 149it [00:04, 35.31it/s]\n",
      "Rows of VAR matrix processed: 149it [00:04, 36.59it/s]\n",
      "Rows of VAR matrix processed: 149it [00:07, 20.69it/s]\n",
      "Rows of VAR matrix processed: 149it [00:07, 20.77it/s]\n",
      "Rows of VAR matrix processed: 149it [00:10, 13.98it/s]\n",
      "Rows of VAR matrix processed: 149it [00:11, 13.41it/s]\n",
      "Rows of VAR matrix processed: 149it [00:18,  8.24it/s]\n",
      "Rows of VAR matrix processed: 149it [00:18,  8.20it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 83.63it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 84.98it/s]\n",
      "Rows of VAR matrix processed: 149it [00:04, 35.93it/s]\n",
      "Rows of VAR matrix processed: 149it [00:04, 36.04it/s]\n",
      "Rows of VAR matrix processed: 149it [00:07, 20.66it/s]\n",
      "Rows of VAR matrix processed: 149it [00:06, 21.47it/s]\n",
      "Rows of VAR matrix processed: 149it [00:11, 13.30it/s]\n",
      "Rows of VAR matrix processed: 149it [00:10, 13.62it/s]\n",
      "Rows of VAR matrix processed: 149it [00:17,  8.29it/s]\n",
      "Rows of VAR matrix processed: 149it [00:17,  8.31it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 84.88it/s]\n",
      "Rows of VAR matrix processed: 149it [00:01, 85.68it/s]\n",
      "Rows of VAR matrix processed: 149it [00:04, 34.65it/s]\n",
      "Rows of VAR matrix processed: 149it [00:04, 35.98it/s]\n",
      "Rows of VAR matrix processed: 149it [00:07, 21.25it/s]\n",
      "Rows of VAR matrix processed: 149it [00:07, 20.97it/s]\n",
      "Rows of VAR matrix processed: 149it [00:10, 13.72it/s]\n",
      "Rows of VAR matrix processed: 149it [00:10, 13.83it/s]\n",
      "Rows of VAR matrix processed: 149it [00:17,  8.44it/s]\n",
      "Rows of VAR matrix processed: 149it [00:17,  8.30it/s]\n",
      " 60%|██████    | 3/5 [2:09:59<1:09:58, 2099.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:31<00:00, 31.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34663.67it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 173it [00:17,  9.76it/s]\n",
      "Rows of VAR matrix processed: 173it [00:17,  9.88it/s]\n",
      "Rows of VAR matrix processed: 173it [00:40,  4.26it/s]\n",
      "Rows of VAR matrix processed: 173it [00:40,  4.24it/s]\n",
      "Rows of VAR matrix processed: 173it [01:02,  2.76it/s]\n",
      "Rows of VAR matrix processed: 173it [01:02,  2.78it/s]\n",
      "Rows of VAR matrix processed: 173it [01:44,  1.66it/s]\n",
      "Rows of VAR matrix processed: 173it [01:45,  1.65it/s]\n",
      "Rows of VAR matrix processed: 173it [02:22,  1.22it/s]\n",
      "Rows of VAR matrix processed: 173it [02:22,  1.21it/s]\n",
      "Rows of VAR matrix processed: 173it [00:18,  9.27it/s]\n",
      "Rows of VAR matrix processed: 173it [00:18,  9.50it/s]\n",
      "Rows of VAR matrix processed: 173it [00:40,  4.28it/s]\n",
      "Rows of VAR matrix processed: 173it [00:41,  4.22it/s]\n",
      "Rows of VAR matrix processed: 173it [01:02,  2.76it/s]\n",
      "Rows of VAR matrix processed: 173it [01:03,  2.74it/s]\n",
      "Rows of VAR matrix processed: 173it [01:44,  1.65it/s]\n",
      "Rows of VAR matrix processed: 173it [01:44,  1.66it/s]\n",
      "Rows of VAR matrix processed: 173it [02:22,  1.21it/s]\n",
      "Rows of VAR matrix processed: 173it [02:22,  1.22it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 173it [00:18,  9.54it/s]\n",
      "Rows of VAR matrix processed: 173it [00:18,  9.44it/s]\n",
      "Rows of VAR matrix processed: 173it [00:40,  4.23it/s]\n",
      "Rows of VAR matrix processed: 173it [00:40,  4.23it/s]\n",
      "Rows of VAR matrix processed: 173it [01:03,  2.71it/s]\n",
      "Rows of VAR matrix processed: 173it [01:03,  2.74it/s]\n",
      "Rows of VAR matrix processed: 173it [01:43,  1.68it/s]\n",
      "Rows of VAR matrix processed: 173it [01:43,  1.67it/s]\n",
      "Rows of VAR matrix processed: 173it [02:26,  1.18it/s]\n",
      "Rows of VAR matrix processed: 173it [02:26,  1.18it/s]\n",
      "Rows of VAR matrix processed: 173it [00:18,  9.45it/s]\n",
      "Rows of VAR matrix processed: 173it [00:18,  9.30it/s]\n",
      "Rows of VAR matrix processed: 173it [00:41,  4.21it/s]\n",
      "Rows of VAR matrix processed: 173it [00:40,  4.29it/s]\n",
      "Rows of VAR matrix processed: 173it [01:03,  2.73it/s]\n",
      "Rows of VAR matrix processed: 173it [01:03,  2.73it/s]\n",
      "Rows of VAR matrix processed: 173it [01:42,  1.68it/s]\n",
      "Rows of VAR matrix processed: 173it [01:43,  1.67it/s]\n",
      "Rows of VAR matrix processed: 173it [02:25,  1.19it/s]\n",
      "Rows of VAR matrix processed: 173it [02:26,  1.18it/s]\n",
      "Rows of VAR matrix processed: 173it [00:17,  9.61it/s]\n",
      "Rows of VAR matrix processed: 173it [00:18,  9.61it/s]\n",
      "Rows of VAR matrix processed: 173it [00:40,  4.29it/s]\n",
      "Rows of VAR matrix processed: 173it [00:40,  4.26it/s]\n",
      "Rows of VAR matrix processed: 173it [01:03,  2.72it/s]\n",
      "Rows of VAR matrix processed: 173it [01:03,  2.74it/s]\n",
      "Rows of VAR matrix processed: 173it [01:43,  1.68it/s]\n",
      "Rows of VAR matrix processed: 173it [01:43,  1.67it/s]\n",
      "Rows of VAR matrix processed: 173it [02:26,  1.18it/s]\n",
      "Rows of VAR matrix processed: 173it [02:26,  1.18it/s]\n",
      " 80%|████████  | 4/5 [3:12:26<45:49, 2749.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34663.67it/s]\n",
      "Rows of VAR matrix processed: 97it [00:01, 52.02it/s]\n",
      "Rows of VAR matrix processed: 97it [00:01, 51.60it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 22.47it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 20.91it/s]\n",
      "Rows of VAR matrix processed: 97it [00:07, 12.56it/s]\n",
      "Rows of VAR matrix processed: 97it [00:07, 12.47it/s]\n",
      "Rows of VAR matrix processed: 97it [00:10,  8.89it/s]\n",
      "Rows of VAR matrix processed: 97it [00:10,  8.98it/s]\n",
      "Rows of VAR matrix processed: 97it [00:14,  6.92it/s]\n",
      "Rows of VAR matrix processed: 97it [00:14,  6.64it/s]\n",
      "Rows of VAR matrix processed: 97it [00:02, 46.37it/s]\n",
      "Rows of VAR matrix processed: 97it [00:02, 46.27it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 20.78it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 20.78it/s]\n",
      "Rows of VAR matrix processed: 97it [00:08, 12.12it/s]\n",
      "Rows of VAR matrix processed: 97it [00:07, 12.36it/s]\n",
      "Rows of VAR matrix processed: 97it [00:11,  8.69it/s]\n",
      "Rows of VAR matrix processed: 97it [00:11,  8.69it/s]\n",
      "Rows of VAR matrix processed: 97it [00:14,  6.77it/s]\n",
      "Rows of VAR matrix processed: 97it [00:14,  6.68it/s]\n",
      "Rows of VAR matrix processed: 97it [00:01, 51.85it/s]\n",
      "Rows of VAR matrix processed: 97it [00:01, 52.48it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 21.67it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 21.71it/s]\n",
      "Rows of VAR matrix processed: 97it [00:07, 12.38it/s]\n",
      "Rows of VAR matrix processed: 97it [00:07, 12.30it/s]\n",
      "Rows of VAR matrix processed: 97it [00:11,  8.76it/s]\n",
      "Rows of VAR matrix processed: 97it [00:11,  8.74it/s]\n",
      "Rows of VAR matrix processed: 97it [00:14,  6.63it/s]\n",
      "Rows of VAR matrix processed: 97it [00:13,  7.01it/s]\n",
      "Rows of VAR matrix processed: 97it [00:02, 46.02it/s]\n",
      "Rows of VAR matrix processed: 97it [00:02, 47.09it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 21.36it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 20.59it/s]\n",
      "Rows of VAR matrix processed: 97it [00:07, 12.22it/s]\n",
      "Rows of VAR matrix processed: 97it [00:07, 12.54it/s]\n",
      "Rows of VAR matrix processed: 97it [00:11,  8.60it/s]\n",
      "Rows of VAR matrix processed: 97it [00:11,  8.73it/s]\n",
      "Rows of VAR matrix processed: 97it [00:14,  6.74it/s]\n",
      "Rows of VAR matrix processed: 97it [00:13,  6.93it/s]\n",
      "Rows of VAR matrix processed: 97it [00:02, 47.96it/s]\n",
      "Rows of VAR matrix processed: 97it [00:02, 47.05it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 21.71it/s]\n",
      "Rows of VAR matrix processed: 97it [00:04, 20.23it/s]\n",
      "Rows of VAR matrix processed: 97it [00:08, 11.72it/s]\n",
      "Rows of VAR matrix processed: 97it [00:07, 12.39it/s]\n",
      "Rows of VAR matrix processed: 97it [00:11,  8.63it/s]\n",
      "Rows of VAR matrix processed: 97it [00:11,  8.53it/s]\n",
      "Rows of VAR matrix processed: 97it [00:13,  6.97it/s]\n",
      "Rows of VAR matrix processed: 97it [00:13,  6.93it/s]\n",
      "100%|██████████| 5/5 [3:19:20<00:00, 2392.10s/it]\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "for data_file in tqdm(data_files[0:5]):\n",
    "    \n",
    "    dat_M1 = load_sabes(data_file)\n",
    "    dat_S1 = load_sabes(data_file, region='S1')\n",
    "\n",
    "    yM1 = np.squeeze(dat_M1['spike_rates'])\n",
    "    yS1 = np.squeeze(dat_S1['spike_rates'])\n",
    "    yjoint = np.hstack([yM1, yS1])\n",
    "\n",
    "    fold_idx = 0 \n",
    "\n",
    "    # Cross-validated marginal models\n",
    "    for train_idxs, test_idxs in KFold(5).split(yM1):\n",
    "\n",
    "        ccm_trainM1 = estimate_autocorrelation(yM1[train_idxs], 5)\n",
    "        ccm_testM1 = estimate_autocorrelation(yM1[test_idxs], 5)\n",
    "        ccm_trainS1 = estimate_autocorrelation(yS1[train_idxs], 5)\n",
    "        ccm_testS1 = estimate_autocorrelation(yS1[test_idxs], 5)\n",
    "\n",
    "        ccm_train_joint = estimate_autocorrelation(yjoint[train_idxs], 5)\n",
    "        ccm_test_joint = estimate_autocorrelation(yjoint[test_idxs], 5)\n",
    "\n",
    "        for var_order in [1, 2, 3, 4, 5]:\n",
    "            \n",
    "            results = {}\n",
    "            results['data_file'] = data_file\n",
    "            results['fold_idx'] = fold_idx\n",
    "            results['var_order'] = var_order\n",
    "            results['ccm_trainM1'] = ccm_trainM1\n",
    "            results['ccm_testM1'] = ccm_testM1\n",
    "            results['ccm_trainS1'] = ccm_trainS1 \n",
    "            results['ccm_testS1'] = ccm_testS1\n",
    "            results['ccm_train_joint'] = ccm_train_joint\n",
    "            results['ccm_test_joint'] = ccm_test_joint\n",
    "\n",
    "            varmodel = VAR(estimator='ols', order=var_order)\n",
    "            varmodel.fit(yM1[train_idxs])\n",
    "            results['m1_coef'] = varmodel.coef_\n",
    "\n",
    "            varmodel.fit(yS1[train_idxs])\n",
    "            results['s1_coef'] = varmodel.coef_\n",
    "\n",
    "            varmodel.fit(yjoint[train_idxs])\n",
    "            results['joint_coef'] = varmodel.coef_\n",
    "            results_list.append(results)\n",
    "\n",
    "        fold_idx += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sabes_var_fits1.dat', 'wb') as f:\n",
    "    f.write(pickle.dumps(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection stpep. We select based on cross-validated CCM estimation error. First set of questions: Does the model based off the joint regression do better at CCM error than the marginal models?\n",
    "results_list = []\n",
    "\n",
    "etrain_M1 = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "etest_M1 = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "etrain_S1 = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "etest_S1 = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "\n",
    "etrain_joint = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "etest_joint = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "\n",
    "etrain_jointM1 = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "etest_jointM1 = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "etrain_jointS1 = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "etest_jointS1 = np.zeros((len(data_files[0:5]), 5, 5, 5))\n",
    "\n",
    "for i, data_file in enumerate(data_files[0:1]):\n",
    "    for j, fold_idx in enumerate(range(5)):\n",
    "        for k, var_order in enumerate([1, 2, 3, 4, 5]):\n",
    "            df_ = apply_df_filters(df, data_file=data_file, fold_idx=fold_idx, var_order=var_order)\n",
    "            assert(df_.shape[0]) == 1\n",
    "            df_ = df_.iloc[0]\n",
    "\n",
    "            # Marginal and joint autocorrelations \n",
    "            varss_M1 = VARss(df_['m1_coef'])\n",
    "            varss_S1 = VARss(df_['s1_coef'])\n",
    "            varss_joint = VARss(df_['joint_coef'])\n",
    "\n",
    "\n",
    "            if i == 1:\n",
    "                pdb.set_trace()\n",
    "\n",
    "            M1_proj = np.block([[np.eye(varss_M1.C.shape[0]), np.zeros((varss_M1.C.shape[0], varss_S1.C.shape[0]))]])\n",
    "            S1_proj = np.block([[np.zeros((varss_S1.C.shape[0], varss_M1.C.shape[0])), np.eye(varss_S1.C.shape[0])]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            etrain_M1[i, j, k] = [np.linalg.norm(df_['ccm_trainM1'][idx] - varss_M1.autocorrelation(5)[idx]) for idx in range(5)]\n",
    "            etest_M1[i, j, k] = [np.linalg.norm(df_['ccm_testM1'][idx] - varss_M1.autocorrelation(5)[idx]) for idx in range(5)]\n",
    "# Next question: We need to parametrically vary over the time lags that we use to regress the past of one area onto another\n",
    "            if df_['ccm_trainS1'].shape[-1] == 0: \n",
    "                etrain_S1[i, j, k] = 5*[np.nan]\n",
    "                etest_S1[i, j, k] = 5*[np.nan]\n",
    "            else:           \n",
    "                etrain_S1[i, j, k] = [np.linalg.norm(df_['ccm_trainS1'][idx] - varss_S1.autocorrelation(5)[idx]) for idx in range(5)]\n",
    "                etest_S1[i, j, k] = [np.linalg.norm(df_['ccm_testS1'][idx] - varss_S1.autocorrelation(5)[idx]) for idx in range(5)]\n",
    "\n",
    "            etrain_joint[i, j, k] = [np.linalg.norm(df_['ccm_train_joint'][idx] - varss_joint.autocorrelation(5)[idx]) for idx in range(5)]\n",
    "            etest_joint[i, j, k] = [np.linalg.norm(df_['ccm_test_joint'][idx] - varss_joint.autocorrelation(5)[idx]) for idx in range(5)]\n",
    "\n",
    "            etrain_jointM1[i, j, k] = [np.linalg.norm(df_['ccm_trainM1'][idx] - varss_joint.autocorrelation(5, proj=M1_proj)[idx]) for idx in range(5)]\n",
    "            etest_jointM1[i, j, k] = [np.linalg.norm(df_['ccm_testM1'][idx] - varss_joint.autocorrelation(5, proj=M1_proj)[idx]) for idx in range(5)]\n",
    "        \n",
    "\n",
    "            if df_['ccm_trainS1'].shape[-1] == 0: \n",
    "                etrain_jointS1[i, j, k] = 5*[np.nan]\n",
    "                etest_jointS1[i, j, k] = 5*[np.nan]\n",
    "            else:\n",
    "                etrain_jointS1[i, j, k] = [np.linalg.norm(df_['ccm_testS1'][idx] - varss_joint.autocorrelation(5, proj=S1_proj)[idx]) for idx in range(5)]\n",
    "                etest_jointS1[i, j, k] = [np.linalg.norm(df_['ccm_testS1'][idx] - varss_joint.autocorrelation(5, proj=S1_proj)[idx]) for idx in range(5)]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.18709493,  5.93213143,  4.62710963,  4.21830198,  3.94745552],\n",
       "       [11.2293733 ,  5.79794963,  5.05324065,  3.55024075,  3.3089208 ],\n",
       "       [13.74877306,  7.56068938,  6.15302178,  5.51719435,  4.05322118],\n",
       "       [18.36608323, 11.20093005,  9.43139297,  8.02620239,  7.26154032],\n",
       "       [24.10159544, 15.69028094, 13.25797473, 11.29182826,  9.79938752]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(etest_M1[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(etest_M1[0], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.91209349, 28.93972513, 37.03289974, 54.28614896, 74.14106688])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.mean(etest_M1[0], axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.63531864, 28.60276422, 37.42693224, 56.22008037, 78.1036549 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.mean(etest_jointM1[0], axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the loss of performance for longer lags, could look at regularization as an answer. Have Li experiment with subspace identification. What about self regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough draft of Figure 2: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: Calculate the TE between M1 and S1 for different lags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting (peanut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import load_peanut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/mnt/Secondary/data/peanut/data_dict_peanut_day14.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 54it [00:00, 219.35it/s]\n",
      "Rows of VAR matrix processed: 194it [00:05, 35.11it/s]\n",
      "Rows of VAR matrix processed: 248it [00:09, 26.20it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 78.34it/s]\n",
      "Rows of VAR matrix processed: 194it [00:12, 14.96it/s]\n",
      "Rows of VAR matrix processed: 248it [00:20, 11.84it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 54.50it/s]\n",
      "Rows of VAR matrix processed: 194it [00:21,  8.99it/s]\n",
      "Rows of VAR matrix processed: 248it [00:47,  5.27it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 41.46it/s]\n",
      "Rows of VAR matrix processed: 194it [00:34,  5.54it/s]\n",
      "Rows of VAR matrix processed: 248it [00:59,  4.16it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 34.19it/s]\n",
      "Rows of VAR matrix processed: 194it [00:45,  4.25it/s]\n",
      "Rows of VAR matrix processed: 248it [01:30,  2.74it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 54it [00:00, 293.94it/s]\n",
      "Rows of VAR matrix processed: 194it [00:04, 41.44it/s]\n",
      "Rows of VAR matrix processed: 248it [00:07, 32.11it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 118.34it/s]\n",
      "Rows of VAR matrix processed: 194it [00:10, 18.59it/s]\n",
      "Rows of VAR matrix processed: 248it [00:18, 13.37it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 75.66it/s]\n",
      "Rows of VAR matrix processed: 194it [00:17, 11.00it/s]\n",
      "Rows of VAR matrix processed: 248it [00:38,  6.46it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 48.42it/s]\n",
      "Rows of VAR matrix processed: 194it [00:31,  6.11it/s]\n",
      "Rows of VAR matrix processed: 248it [00:59,  4.15it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 31.32it/s]\n",
      "Rows of VAR matrix processed: 194it [00:45,  4.22it/s]\n",
      "Rows of VAR matrix processed: 248it [01:30,  2.75it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 54it [00:00, 293.88it/s]\n",
      "Rows of VAR matrix processed: 194it [00:04, 43.21it/s]\n",
      "Rows of VAR matrix processed: 248it [00:07, 31.46it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 119.52it/s]\n",
      "Rows of VAR matrix processed: 194it [00:10, 18.85it/s]\n",
      "Rows of VAR matrix processed: 248it [00:18, 13.76it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 68.98it/s]\n",
      "Rows of VAR matrix processed: 194it [00:17, 11.06it/s]\n",
      "Rows of VAR matrix processed: 248it [00:38,  6.50it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 51.75it/s]\n",
      "Rows of VAR matrix processed: 194it [00:31,  6.23it/s]\n",
      "Rows of VAR matrix processed: 248it [00:59,  4.18it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 32.81it/s]\n",
      "Rows of VAR matrix processed: 194it [00:45,  4.26it/s]\n",
      "Rows of VAR matrix processed: 248it [01:30,  2.73it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 54it [00:00, 301.46it/s]\n",
      "Rows of VAR matrix processed: 194it [00:04, 43.14it/s]\n",
      "Rows of VAR matrix processed: 248it [00:07, 31.41it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 121.38it/s]\n",
      "Rows of VAR matrix processed: 194it [00:10, 19.37it/s]\n",
      "Rows of VAR matrix processed: 248it [00:17, 13.79it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 71.97it/s]\n",
      "Rows of VAR matrix processed: 194it [00:17, 10.83it/s]\n",
      "Rows of VAR matrix processed: 248it [00:39,  6.33it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 48.69it/s]\n",
      "Rows of VAR matrix processed: 194it [00:31,  6.18it/s]\n",
      "Rows of VAR matrix processed: 248it [00:59,  4.19it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 30.77it/s]\n",
      "Rows of VAR matrix processed: 194it [00:46,  4.21it/s]\n",
      "Rows of VAR matrix processed: 248it [01:30,  2.74it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 54it [00:00, 294.96it/s]\n",
      "Rows of VAR matrix processed: 194it [00:04, 44.67it/s]\n",
      "Rows of VAR matrix processed: 248it [00:07, 32.45it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 120.48it/s]\n",
      "Rows of VAR matrix processed: 194it [00:09, 19.42it/s]\n",
      "Rows of VAR matrix processed: 248it [00:18, 13.73it/s]\n",
      "Rows of VAR matrix processed: 54it [00:00, 66.21it/s]\n",
      "Rows of VAR matrix processed: 194it [00:17, 10.93it/s]\n",
      "Rows of VAR matrix processed: 248it [00:39,  6.24it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 49.83it/s]\n",
      "Rows of VAR matrix processed: 194it [00:31,  6.23it/s]\n",
      "Rows of VAR matrix processed: 248it [00:59,  4.18it/s]\n",
      "Rows of VAR matrix processed: 54it [00:01, 34.78it/s]\n",
      "Rows of VAR matrix processed: 194it [00:46,  4.19it/s]\n",
      "Rows of VAR matrix processed: 248it [01:29,  2.76it/s]\n",
      "1it [28:12, 1692.90s/it]../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 45it [00:00, 259.00it/s]\n",
      "Rows of VAR matrix processed: 208it [00:06, 34.26it/s]\n",
      "Rows of VAR matrix processed: 253it [00:09, 27.79it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 104.25it/s]\n",
      "Rows of VAR matrix processed: 208it [00:13, 15.01it/s]\n",
      "Rows of VAR matrix processed: 253it [00:21, 11.64it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 80.61it/s]\n",
      "Rows of VAR matrix processed: 208it [00:24,  8.46it/s]\n",
      "Rows of VAR matrix processed: 253it [00:44,  5.73it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 47.44it/s]\n",
      "Rows of VAR matrix processed: 208it [00:41,  5.03it/s]\n",
      "Rows of VAR matrix processed: 253it [01:16,  3.30it/s]\n",
      "Rows of VAR matrix processed: 45it [00:01, 33.04it/s]\n",
      "Rows of VAR matrix processed: 208it [01:11,  2.93it/s]\n",
      "Rows of VAR matrix processed: 253it [01:59,  2.11it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 45it [00:00, 251.73it/s]\n",
      "Rows of VAR matrix processed: 208it [00:06, 31.84it/s]\n",
      "Rows of VAR matrix processed: 253it [00:10, 24.07it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 88.24it/s]\n",
      "Rows of VAR matrix processed: 208it [00:16, 12.82it/s]\n",
      "Rows of VAR matrix processed: 253it [00:24, 10.13it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 67.29it/s]\n",
      "Rows of VAR matrix processed: 208it [00:28,  7.29it/s]\n",
      "Rows of VAR matrix processed: 253it [00:50,  4.98it/s]\n",
      "Rows of VAR matrix processed: 45it [00:01, 44.48it/s]\n",
      "Rows of VAR matrix processed: 208it [00:48,  4.29it/s]\n",
      "Rows of VAR matrix processed: 253it [01:22,  3.09it/s]\n",
      "Rows of VAR matrix processed: 45it [00:01, 34.86it/s]\n",
      "Rows of VAR matrix processed: 208it [01:11,  2.92it/s]\n",
      "Rows of VAR matrix processed: 253it [01:59,  2.11it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 45it [00:00, 255.37it/s]\n",
      "Rows of VAR matrix processed: 208it [00:06, 29.92it/s]\n",
      "Rows of VAR matrix processed: 253it [00:10, 23.71it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 95.40it/s] \n",
      "Rows of VAR matrix processed: 208it [00:16, 12.59it/s]\n",
      "Rows of VAR matrix processed: 253it [00:25,  9.96it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 61.02it/s]\n",
      "Rows of VAR matrix processed: 208it [00:28,  7.37it/s]\n",
      "Rows of VAR matrix processed: 253it [00:50,  5.00it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 48.67it/s]\n",
      "Rows of VAR matrix processed: 208it [00:49,  4.22it/s]\n",
      "Rows of VAR matrix processed: 253it [01:22,  3.08it/s]\n",
      "Rows of VAR matrix processed: 45it [00:01, 35.13it/s]\n",
      "Rows of VAR matrix processed: 208it [01:12,  2.89it/s]\n",
      "Rows of VAR matrix processed: 253it [01:59,  2.12it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 45it [00:00, 241.57it/s]\n",
      "Rows of VAR matrix processed: 208it [00:06, 30.71it/s]\n",
      "Rows of VAR matrix processed: 253it [00:10, 24.16it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 84.77it/s]\n",
      "Rows of VAR matrix processed: 208it [00:16, 12.62it/s]\n",
      "Rows of VAR matrix processed: 253it [00:25,  9.82it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 60.68it/s]\n",
      "Rows of VAR matrix processed: 208it [00:28,  7.26it/s]\n",
      "Rows of VAR matrix processed: 253it [00:51,  4.89it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 50.16it/s]\n",
      "Rows of VAR matrix processed: 208it [00:48,  4.30it/s]\n",
      "Rows of VAR matrix processed: 253it [01:22,  3.08it/s]\n",
      "Rows of VAR matrix processed: 45it [00:01, 35.76it/s]\n",
      "Rows of VAR matrix processed: 208it [01:10,  2.96it/s]\n",
      "Rows of VAR matrix processed: 253it [01:58,  2.13it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 45it [00:00, 262.39it/s]\n",
      "Rows of VAR matrix processed: 208it [00:06, 30.42it/s]\n",
      "Rows of VAR matrix processed: 253it [00:10, 24.16it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 97.75it/s]\n",
      "Rows of VAR matrix processed: 208it [00:16, 12.80it/s]\n",
      "Rows of VAR matrix processed: 253it [00:25, 10.07it/s]\n",
      "Rows of VAR matrix processed: 45it [00:00, 70.63it/s]\n",
      "Rows of VAR matrix processed: 208it [00:28,  7.20it/s]\n",
      "Rows of VAR matrix processed: 253it [00:51,  4.89it/s]\n",
      "Rows of VAR matrix processed: 45it [00:01, 44.09it/s]\n",
      "Rows of VAR matrix processed: 208it [00:48,  4.33it/s]\n",
      "Rows of VAR matrix processed: 253it [01:21,  3.09it/s]\n",
      "Rows of VAR matrix processed: 45it [00:01, 33.27it/s]\n",
      "Rows of VAR matrix processed: 208it [01:12,  2.88it/s]\n",
      "Rows of VAR matrix processed: 253it [01:59,  2.12it/s]\n",
      "2it [1:06:48, 2058.91s/it]../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 43it [00:00, 320.14it/s]\n",
      "Rows of VAR matrix processed: 203it [00:05, 34.21it/s]\n",
      "Rows of VAR matrix processed: 246it [00:09, 26.74it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 101.81it/s]\n",
      "Rows of VAR matrix processed: 203it [00:14, 14.43it/s]\n",
      "Rows of VAR matrix processed: 246it [00:21, 11.55it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 79.85it/s]\n",
      "Rows of VAR matrix processed: 203it [00:24,  8.16it/s]\n",
      "Rows of VAR matrix processed: 246it [00:45,  5.37it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 59.57it/s]\n",
      "Rows of VAR matrix processed: 203it [00:41,  4.89it/s]\n",
      "Rows of VAR matrix processed: 246it [01:10,  3.51it/s]\n",
      "Rows of VAR matrix processed: 43it [00:01, 42.21it/s]\n",
      "Rows of VAR matrix processed: 203it [01:03,  3.22it/s]\n",
      "Rows of VAR matrix processed: 246it [01:47,  2.28it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 43it [00:00, 277.77it/s]\n",
      "Rows of VAR matrix processed: 203it [00:06, 33.27it/s]\n",
      "Rows of VAR matrix processed: 246it [00:09, 25.03it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 116.47it/s]\n",
      "Rows of VAR matrix processed: 203it [00:14, 14.16it/s]\n",
      "Rows of VAR matrix processed: 246it [00:22, 11.17it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 78.21it/s]\n",
      "Rows of VAR matrix processed: 203it [00:24,  8.34it/s]\n",
      "Rows of VAR matrix processed: 246it [00:46,  5.33it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 50.84it/s]\n",
      "Rows of VAR matrix processed: 203it [00:44,  4.56it/s]\n",
      "Rows of VAR matrix processed: 246it [01:14,  3.31it/s]\n",
      "Rows of VAR matrix processed: 43it [00:01, 37.03it/s]\n",
      "Rows of VAR matrix processed: 203it [01:08,  2.94it/s]\n",
      "Rows of VAR matrix processed: 246it [01:44,  2.35it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 43it [00:00, 333.32it/s]\n",
      "Rows of VAR matrix processed: 203it [00:05, 34.61it/s]\n",
      "Rows of VAR matrix processed: 246it [00:09, 26.55it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 123.03it/s]\n",
      "Rows of VAR matrix processed: 203it [00:12, 15.87it/s]\n",
      "Rows of VAR matrix processed: 246it [00:20, 12.03it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 83.64it/s]\n",
      "Rows of VAR matrix processed: 203it [00:23,  8.69it/s]\n",
      "Rows of VAR matrix processed: 246it [00:41,  5.88it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 60.35it/s]\n",
      "Rows of VAR matrix processed: 203it [00:39,  5.15it/s]\n",
      "Rows of VAR matrix processed: 246it [01:03,  3.86it/s]\n",
      "Rows of VAR matrix processed: 43it [00:01, 39.52it/s]\n",
      "Rows of VAR matrix processed: 203it [00:53,  3.80it/s]\n",
      "Rows of VAR matrix processed: 246it [01:33,  2.62it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 43it [00:00, 366.82it/s]\n",
      "Rows of VAR matrix processed: 203it [00:05, 35.86it/s]\n",
      "Rows of VAR matrix processed: 246it [00:08, 27.93it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 145.41it/s]\n",
      "Rows of VAR matrix processed: 203it [00:12, 16.02it/s]\n",
      "Rows of VAR matrix processed: 246it [00:19, 12.69it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 90.64it/s]\n",
      "Rows of VAR matrix processed: 203it [00:21,  9.35it/s]\n",
      "Rows of VAR matrix processed: 246it [00:40,  6.14it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 65.81it/s]\n",
      "Rows of VAR matrix processed: 203it [00:37,  5.48it/s]\n",
      "Rows of VAR matrix processed: 246it [01:02,  3.95it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 44.97it/s]\n",
      "Rows of VAR matrix processed: 203it [00:55,  3.67it/s]\n",
      "Rows of VAR matrix processed: 246it [01:35,  2.57it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 43it [00:00, 352.95it/s]\n",
      "Rows of VAR matrix processed: 203it [00:05, 36.27it/s]\n",
      "Rows of VAR matrix processed: 246it [00:08, 29.22it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 127.96it/s]\n",
      "Rows of VAR matrix processed: 203it [00:12, 16.06it/s]\n",
      "Rows of VAR matrix processed: 246it [00:20, 12.20it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 86.89it/s]\n",
      "Rows of VAR matrix processed: 203it [00:21,  9.33it/s]\n",
      "Rows of VAR matrix processed: 246it [00:40,  6.02it/s]\n",
      "Rows of VAR matrix processed: 43it [00:00, 68.33it/s]\n",
      "Rows of VAR matrix processed: 203it [00:37,  5.41it/s]\n",
      "Rows of VAR matrix processed: 246it [01:02,  3.95it/s]\n",
      "Rows of VAR matrix processed: 43it [00:01, 42.12it/s]\n",
      "Rows of VAR matrix processed: 203it [00:52,  3.84it/s]\n",
      "Rows of VAR matrix processed: 246it [01:33,  2.63it/s]\n",
      "3it [1:39:06, 2003.84s/it]../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 53it [00:00, 238.02it/s]\n",
      "Rows of VAR matrix processed: 198it [00:05, 37.98it/s]\n",
      "Rows of VAR matrix processed: 251it [00:09, 27.79it/s]\n",
      "Rows of VAR matrix processed: 53it [00:00, 85.98it/s]\n",
      "Rows of VAR matrix processed: 198it [00:12, 15.76it/s]\n",
      "Rows of VAR matrix processed: 251it [00:21, 11.65it/s]\n",
      "Rows of VAR matrix processed: 53it [00:00, 56.72it/s]\n",
      "Rows of VAR matrix processed: 198it [00:21,  9.02it/s]\n",
      "Rows of VAR matrix processed: 251it [00:43,  5.77it/s]\n",
      "Rows of VAR matrix processed: 53it [00:01, 39.99it/s]\n",
      "Rows of VAR matrix processed: 198it [00:37,  5.34it/s]\n",
      "Rows of VAR matrix processed: 251it [01:09,  3.61it/s]\n",
      "Rows of VAR matrix processed: 53it [00:01, 28.05it/s]\n",
      "Rows of VAR matrix processed: 198it [00:52,  3.74it/s]\n",
      "Rows of VAR matrix processed: 251it [01:41,  2.47it/s]\n",
      "../../cov_estimation.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ccm_sample_normalized[k, i, j] /= np.sqrt(ccm_sample[0, i, i] * ccm_sample[0, j, j])\n",
      "Rows of VAR matrix processed: 53it [00:00, 247.76it/s]\n",
      "Rows of VAR matrix processed: 198it [00:05, 36.32it/s]\n",
      "Rows of VAR matrix processed: 251it [00:09, 27.32it/s]\n",
      "Rows of VAR matrix processed: 53it [00:00, 100.76it/s]\n",
      "Rows of VAR matrix processed: 198it [00:12, 15.87it/s]\n",
      "Rows of VAR matrix processed: 251it [00:21, 11.78it/s]\n",
      "Rows of VAR matrix processed: 53it [00:00, 64.62it/s]\n",
      "Rows of VAR matrix processed: 198it [00:22,  8.96it/s]\n",
      "Rows of VAR matrix processed: 251it [00:42,  5.85it/s]\n",
      "Rows of VAR matrix processed: 53it [00:01, 43.46it/s]\n",
      "Rows of VAR matrix processed: 198it [00:35,  5.53it/s]\n",
      "Rows of VAR matrix processed: 251it [01:08,  3.68it/s]\n",
      "Rows of VAR matrix processed: 53it [00:01, 32.09it/s]\n",
      "Rows of VAR matrix processed: 198it [00:54,  3.60it/s]\n",
      "Rows of VAR matrix processed: 34it [00:17,  2.00it/s]\n",
      "3it [1:50:41, 2213.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31902/445905208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's1_coef'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvarmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mvarmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myjoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'joint_coef'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvarmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mresults_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nse/PyUoI/pyuoi/linear_model/var.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y, distributed_save, savepath, resume)\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_regress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nse/PyUoI/pyuoi/linear_model/var.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_mask)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAR_OLS_Wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandalone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dyn/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_residues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingular_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                 \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dyn/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_lwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlapack_lwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 x, s, rank, info = lapack_func(a1, b1, lwork,\n\u001b[0;32m-> 1205\u001b[0;31m                                                iwork, cond, False, False)\n\u001b[0m\u001b[1;32m   1206\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# complex data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m                 lwork, rwork, iwork = _compute_lwork(lapack_lwork, m, n,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "\n",
    "for i, epoch in tqdm(enumerate(np.arange(2, 18, 2))):\n",
    "    dat_HPC = load_peanut(data_file, epoch, spike_threshold=200, region='HPc')\n",
    "    dat_OFC = load_peanut(data_file, epoch, spike_threshold=100, region='OFC')\n",
    "\n",
    "    yM1 = np.squeeze(dat_HPC['spike_rates'])\n",
    "    yS1 = np.squeeze(dat_OFC['spike_rates'])\n",
    "    yjoint = np.hstack([yM1, yS1])\n",
    "\n",
    "    fold_idx = 0 \n",
    "\n",
    "    # Cross-validated marginal models\n",
    "    for train_idxs, test_idxs in KFold(5).split(yM1):\n",
    "\n",
    "        ccm_trainM1 = estimate_autocorrelation(yM1[train_idxs], 5)\n",
    "        ccm_testM1 = estimate_autocorrelation(yM1[test_idxs], 5)\n",
    "        ccm_trainS1 = estimate_autocorrelation(yS1[train_idxs], 5)\n",
    "        ccm_testS1 = estimate_autocorrelation(yS1[test_idxs], 5)\n",
    "\n",
    "        ccm_train_joint = estimate_autocorrelation(yjoint[train_idxs], 5)\n",
    "        ccm_test_joint = estimate_autocorrelation(yjoint[test_idxs], 5)    dat_M1 = load_peanut(data_file, epoch, spike_threshold=200)\n",
    "\n",
    "\n",
    "\n",
    "        for var_order in [1, 2, 3, 4, 5]:\n",
    "            \n",
    "            results = {}\n",
    "            results['data_file'] = data_file\n",
    "            results['fold_idx'] = fold_idx\n",
    "            results['var_order'] = var_order\n",
    "            results['ccm_trainM1'] = ccm_trainM1\n",
    "            results['ccm_testM1'] = ccm_testM1\n",
    "            results['ccm_trainS1'] = ccm_trainS1 \n",
    "            results['ccm_testS1'] = ccm_testS1\n",
    "            results['ccm_train_joint'] = ccm_train_joint\n",
    "            results['ccm_test_joint'] = ccm_test_joint\n",
    "\n",
    "            varmodel = VAR(estimator='ols', order=var_order)\n",
    "            varmodel.fit(yM1[train_idxs])\n",
    "            results['m1_coef'] = varmodel.coef_\n",
    "\n",
    "            varmodel.fit(yS1[train_idxs])\n",
    "            results['s1_coef'] = varmodel.coef_\n",
    "\n",
    "            varmodel.fit(yjoint[train_idxs])\n",
    "            results['joint_coef'] = varmodel.coef_\n",
    "            results_list.append(results)\n",
    "\n",
    "        fold_idx += 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting (PVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c52494c424e88c3f855a8aeb34b231af4706f7aa247f66fb47c890a5ab8814ab"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('dyn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
